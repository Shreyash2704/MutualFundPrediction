{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "historic-keyboard",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from sklearn import preprocessing, svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "cultural-cancer",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ConvertDateintoDay_Month_Year(df):\n",
    "    newdf = pd.DataFrame()\n",
    "    df.Date = pd.to_datetime(df.Date)\n",
    "    newdf[\"Nav\"] = df.Nav\n",
    "    newdf[\"day\"] = df.Date.dt.day\n",
    "    newdf[\"month\"] = df.Date.dt.month\n",
    "    newdf[\"year\"] = df.Date.dt.year\n",
    "    return newdf\n",
    "def OptimiseDataframe(df):\n",
    "    newdf = pd.DataFrame()\n",
    "    newdf[\"Date\"] = df.Date\n",
    "    newdf[\"Nav\"] = df.Open\n",
    "    newdf.dropna()\n",
    "    return newdf\n",
    "def PredictBestMutualFund(day,month,year,duration,algo):\n",
    "    start = []\n",
    "    end = []\n",
    "    ans_start = []\n",
    "    ans_end = []\n",
    "    ans = []\n",
    "    m = duration[0]\n",
    "    y = duration[1]\n",
    "    \n",
    "    ele = (month+m)//12\n",
    "    m = (month+m)%13\n",
    "    y =y+ele+year\n",
    "    \n",
    "    input_start = [[day,month,year]]*len(algo)\n",
    "    input_end = [[day,m,y]]*len(algo)\n",
    "    for i in range(len(algo)):\n",
    "        x = input_start[i].copy()\n",
    "        start.append(x)\n",
    "        y = input_end[i].copy()\n",
    "        end.append(y)\n",
    "    \n",
    "    for i in range(len(start)):\n",
    "        x = algo[i].predict([start[i]])\n",
    "        y = algo[i].predict([end[i]])\n",
    "        ans_start.append(x[0])\n",
    "        ans_end.append(y[0])\n",
    "        ans.append(CalculateReturn(x[0],y[0]))\n",
    "        \n",
    "    print(start,\"\\n\\n\",end)\n",
    "    print(\"-------------------------\")\n",
    "    print(ans_start,\"\\n\\n\",ans_end)\n",
    "    print(\"-------------------------\")\n",
    "    new_ans = [ans_end[i]-ans_start[i] for i in range(len(ans_start))]\n",
    "    print(new_ans)\n",
    "    print(\"-------------------------\")\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "tender-smart",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CalculateReturn(start,end):\n",
    "    returns = (end-start)/start\n",
    "    returns = returns*100\n",
    "    return returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "informational-republican",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_ = os.getcwd()\n",
    "dir_ = os.path.join(dir_,\"dataset\")\n",
    "dir_ = os.listdir(dir_)\n",
    "csv_file = [ele for ele in dir_ if \".csv\" in ele]\n",
    "\n",
    "l = []\n",
    "directory =  os.path.join(os.getcwd(),\"dataset\")\n",
    "for i in csv_file:\n",
    "    df = pd.read_csv(os.path.join(directory,i))\n",
    "    l.append(df)\n",
    "    \n",
    "df_list = []\n",
    "for i in range(len(l)):\n",
    "    newdf = OptimiseDataframe(l[i])\n",
    "    newdf = newdf.dropna()\n",
    "    df_list.append(newdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "random-crazy",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df_list =[]\n",
    "for i in range(len(df_list)):\n",
    "    new_df = ConvertDateintoDay_Month_Year(df_list[i])\n",
    "    new_df_list.append(new_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "animal-interim",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR Model 0 :  0.8985593288089925\n",
      "LR Model 1 :  0.908807336959529\n",
      "LR Model 2 :  0.8978374961970118\n",
      "LR Model 3 :  0.9014599475882349\n",
      "LR Model 4 :  0.902876227193987\n",
      "LR Model 5 :  0.9127670432060478\n",
      "LR Model 6 :  0.9073168221410625\n",
      "LR Model 7 :  0.8971509692044437\n",
      "LR Model 8 :  0.8981952880357563\n",
      "LR Model 9 :  0.888369645744664\n"
     ]
    }
   ],
   "source": [
    "lr_model_list = []\n",
    "for i in range(len(new_df_list)):\n",
    "    y = new_df_list[i][\"Nav\"]\n",
    "    X = new_df_list[i].drop([\"Nav\"],axis=1)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25)\n",
    "    regr = LinearRegression()\n",
    "    regr.fit(X_train, y_train)\n",
    "    print(\"LR Model \"+str(i)+\" : \",regr.score(X_test, y_test))\n",
    "    lr_model_list.append(regr)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "limited-poster",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[23, 2, 2023], [23, 2, 2023], [23, 2, 2023], [23, 2, 2023], [23, 2, 2023], [23, 2, 2023], [23, 2, 2023], [23, 2, 2023], [23, 2, 2023], [23, 2, 2023]] \n",
      "\n",
      " [[23, 7, 2024], [23, 7, 2024], [23, 7, 2024], [23, 7, 2024], [23, 7, 2024], [23, 7, 2024], [23, 7, 2024], [23, 7, 2024], [23, 7, 2024], [23, 7, 2024]]\n",
      "-------------------------\n",
      "[138.62955336333835, 139.34195179474045, 140.1411949489775, 139.87889195886964, 139.22260675265716, 139.04767636106408, 139.55812149549456, 138.27635750498303, 139.78252852162404, 138.77472023609153] \n",
      "\n",
      " [180.03797129348095, 181.5508792805049, 182.67593367787777, 181.66153103001125, 180.60144839408167, 180.89749237403885, 181.8351355988998, 179.95423551449494, 181.76594342408498, 180.44133394242817]\n",
      "-------------------------\n",
      "[41.408417930142605, 42.208927485764434, 42.534738728900265, 41.7826390711416, 41.378841641424515, 41.84981601297477, 42.277014103405236, 41.677878009511915, 41.983414902460936, 41.66661370633665]\n",
      "-------------------------\n",
      "[29.86983433583894, 30.291614938723455, 30.351345829744268, 29.870581962736363, 29.721352448843426, 30.09745801454723, 30.29348177688827, 30.141000791122213, 30.034808603398666, 30.02464255409848]\n",
      "30.351345829744268\n"
     ]
    }
   ],
   "source": [
    "ans_list = PredictBestMutualFund(23,2,2023,[5,1],lr_model_list)\n",
    "print(ans_list)\n",
    "print(max(ans_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "viral-employment",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_max_return_fund(l):\n",
    "    max_return = 0\n",
    "    index = -1\n",
    "    for i in range(len(l)):\n",
    "        if l[i]>max_return:\n",
    "            max_return = l[i]\n",
    "            index = i\n",
    "    return [max_return,index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "negative-concentrate",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30.351345829744268, 2]\n"
     ]
    }
   ],
   "source": [
    "print(get_max_return_fund(ans_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "lyric-productivity",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SBI Equity Hybrid Fund.csv\n"
     ]
    }
   ],
   "source": [
    "print(csv_file[get_max_return_fund(ans_list)[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "unable-crack",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "for i in range(len(lr_model_list)):\n",
    "    name = csv_file[i]\n",
    "    name = name.split(\".\")[0]\n",
    "    name = name+\" model.pkl\"\n",
    "    file = open(name, 'wb')\n",
    "    # dump information to that file\n",
    "    pickle.dump(lr_model_list[i], file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "successful-grammar",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sbi consumption opportunities fund.csv',\n",
       " 'sbi contra fund.csv',\n",
       " 'SBI Equity Hybrid Fund.csv',\n",
       " 'sbi focused fund.csv',\n",
       " 'sbi healthcare opportunities fund.csv',\n",
       " 'SBI Large & Midcap Fund.csv',\n",
       " 'SBI Magnum Equity ESG Fund.csv',\n",
       " 'SBI Magnum Income Fund.csv',\n",
       " 'SBI Nifty Index Fund.csv',\n",
       " 'sbi small cap.csv']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "happy-attention",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR Model 0 :  0.9969995265514571\n",
      "LR Model 1 :  0.9984541552058925\n",
      "LR Model 2 :  0.9971751976506348\n",
      "LR Model 3 :  0.9983824789106962\n",
      "LR Model 4 :  0.9984202517680367\n",
      "LR Model 5 :  0.9986689831144804\n",
      "LR Model 6 :  0.9984704362759232\n",
      "LR Model 7 :  0.998685288888299\n",
      "LR Model 8 :  0.9983964153576629\n",
      "LR Model 9 :  0.9982961783474464\n"
     ]
    }
   ],
   "source": [
    "rnd_fr_model_list = []\n",
    "for i in range(len(new_df_list)):\n",
    "    y = new_df_list[i][\"Nav\"]\n",
    "    X = new_df_list[i].drop([\"Nav\"],axis=1)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25)\n",
    "    regr = RandomForestRegressor()\n",
    "    regr.fit(X_train, y_train)\n",
    "    print(\"LR Model \"+str(i)+\" : \",regr.score(X_test, y_test))\n",
    "    rnd_fr_model_list.append(regr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "twenty-musical",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[23, 11, 2021], [23, 11, 2021], [23, 11, 2021], [23, 11, 2021], [23, 11, 2021], [23, 11, 2021], [23, 11, 2021], [23, 11, 2021], [23, 11, 2021], [23, 11, 2021]] \n",
      "\n",
      " [[23, 6, 2022], [23, 6, 2022], [23, 6, 2022], [23, 6, 2022], [23, 6, 2022], [23, 6, 2022], [23, 6, 2022], [23, 6, 2022], [23, 6, 2022], [23, 6, 2022]]\n",
      "-------------------------\n",
      "[115.1459281199999, 115.47326637999996, 115.38734226999985, 115.69810163999989, 115.38443829999986, 115.27916125999985, 115.44161836999993, 115.41226355999984, 115.39811426999984, 115.43279629999982] \n",
      "\n",
      " [105.49484558000003, 106.02612061999987, 106.4176715600001, 105.42165014000007, 106.37299470999994, 105.05026923999992, 105.59251043000009, 105.06703760999993, 105.51785529000003, 105.24322234000009]\n",
      "-------------------------\n",
      "[-9.651082539999862, -9.447145760000083, -8.969670709999747, -10.276451499999823, -9.011443589999914, -10.228892019999932, -9.84910793999984, -10.345225949999914, -9.880258979999809, -10.189573959999734]\n",
      "-------------------------\n",
      "[-8.381609925400003, -8.181240607597756, -7.77353090342546, -8.882126287582045, -7.809929764159475, -8.873149238941597, -8.531678677989973, -8.963714626931045, -8.561889457641154, -8.827278110388937]\n"
     ]
    }
   ],
   "source": [
    "ans_list = PredictBestMutualFund(23,11,2021,[8,0],rnd_fr_model_list)\n",
    "print(ans_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "statistical-honolulu",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[256.3870417359191, 2]\n",
      "SBI Equity Hybrid Fund.csv\n"
     ]
    }
   ],
   "source": [
    "print(get_max_return_fund(ans_list))\n",
    "print(csv_file[get_max_return_fund(ans_list)[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "composite-beach",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_model_list[9].predict([[23,12,2019]])\n",
    "file = open(\"SBI small cap model.pkl\", 'wb')\n",
    "# dump information to that file\n",
    "pickle.dump(lr_model_list[9], file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "polish-celebrity",
   "metadata": {},
   "source": [
    "# "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
